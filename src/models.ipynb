{"cells":[{"cell_type":"markdown","metadata":{"id":"Y5gaITJJWpWg"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUaF7BguWpWj"},"outputs":[],"source":["# ML imports\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","# Data analysis and stats imports\n","import numpy as np\n","from scipy.stats import expon, reciprocal\n","\n","# Data visualization imports\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from common_language import _LANGUAGES\n","import processing as prlib\n","import train_models as trainer"]},{"cell_type":"markdown","metadata":{"id":"v_PVynMYWpWn"},"source":["### Get data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xir3lwlCWpWn"},"outputs":[],"source":["full_df, train_df, test_df, validation_df = prlib.get_preprocessed_data()\n","df_without_label = full_df.iloc[:, :-1]\n","df_without_label"]},{"cell_type":"markdown","metadata":{},"source":["Relabeling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# relabel by types of language, to group similar languages in one class\n","print(full_df['label'].unique())\n","group_labels = {\n","    'Arabic': 'Languages of the Caucasus and Middle East', 'Basque': 'Other European Languages',\n","    'Breton': 'Constructed and Isolate Languages', 'Catalan': 'Other European Languages',\n","    'Chinese_China': 'East Asian Languages', 'Chinese_Hongkong': 'East Asian Languages',\n","    'Chinese_Taiwan': 'East Asian Languages', 'Chuvash': 'Turkic Languages',\n","    'Czech': 'Slavic Languages', 'Dhivehi': 'Diverse Asian and Pacific Languages',\n","    'Dutch': 'Germanic Languages', 'English': 'Germanic Languages',\n","    'Esperanto': 'Constructed and Isolate Languages', 'Estonian': 'Other European Languages',\n","    'French': 'Romance European Languages', 'Frisian': 'African and Other Languages',\n","    'Georgian': 'Languages of the Caucasus and Middle East', 'German': 'Germanic Languages',\n","    'Greek': 'Romance European Languages', 'Hakha_Chin': 'Diverse Asian and Pacific Languages',\n","    'Indonesian': 'Diverse Asian and Pacific Languages', 'Interlingua': 'Constructed and Isolate Languages',\n","    'Italian': 'Romance European Languages', 'Japanese': 'East Asian Languages',\n","    'Kabyle': 'African and Other Languages', 'Kinyarwanda': 'African and Other Languages',\n","    'Kyrgyz': 'Turkic Languages', 'Latvian': 'Other European Languages',\n","    'Maltese': 'Languages of the Caucasus and Middle East', 'Mongolian': 'Diverse Asian and Pacific Languages',\n","    'Persian': 'Languages of the Caucasus and Middle East', 'Polish': 'Slavic Languages',\n","    'Portuguese': 'Romance European Languages', 'Romanian': 'Romance European Languages',\n","    'Romansh_Sursilvan': 'Constructed and Isolate Languages', 'Russian': 'Slavic Languages',\n","    'Sakha': 'Turkic Languages', 'Slovenian': 'Slavic Languages',\n","    'Spanish': 'Romance European Languages', 'Swedish': 'Germanic Languages',\n","    'Tamil': 'African and Other Languages', 'Tatar': 'Turkic Languages',\n","    'Turkish': 'Turkic Languages', 'Ukranian': 'Slavic Languages', 'Welsh': 'Other European Languages'\n","}\n","\n","# Apply the mapping to the DataFrame\n","#full_df['label'] = full_df['label'].map(group_labels)\n","#print(full_df['label'].unique())\n","#full_df.groupby('label').count()"]},{"cell_type":"markdown","metadata":{"id":"eQQQHH4YWpWo"},"source":["Check multicolinearity"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":861},"executionInfo":{"elapsed":3372,"status":"ok","timestamp":1712925011109,"user":{"displayName":"Sam G.","userId":"13256247437963089201"},"user_tz":240},"id":"m8WjiDgtWpWo","outputId":"61c357bc-9460-4879-fd82-fb444fade9b5"},"outputs":[],"source":["corr = df_without_label.corr()\n","mask = np.triu(np.ones_like(corr, dtype=bool))\n","f, ax = plt.subplots(figsize=(11, 9))\n","cmap = sns.diverging_palette(230, 20, as_cmap=True)\n","sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n","            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"zJ2KG5yEWpWt"},"source":["## Models"]},{"cell_type":"markdown","metadata":{"id":"LN3HvxJ4WpWt"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXJt9YosWpWu"},"outputs":[],"source":["X_train,Y_train, X_test, Y_test = trainer.embedded_data()\n","\n","# Model initialization\n","svm = SVC(verbose=3, kernel='linear', random_state=42)\n","svm_poly = SVC(verbose=3, kernel='poly', random_state=42)\n","svm_rbf = SVC(verbose=3, kernel='rbf', random_state=42)\n","random_forest = RandomForestClassifier(verbose=3, random_state=42)\n","\n","# Models fiting\n","print(\"Training linear SVM\")\n","svm.fit(X_train, Y_train)\n","print()\n","print('Training poly SVM')\n","svm_poly.fit(X_train, Y_train)\n","print()\n","print('Training rbf SVM')\n","svm_rbf.fit(X_train, Y_train)\n","print()\n","print(\"Training RFC\")\n","random_forest.fit(X_train, Y_train)\n"]},{"cell_type":"markdown","metadata":{"id":"4Fi4vMynWpWu"},"source":["### Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3LreXv0WpWu"},"outputs":[],"source":["# Models prediction\n","svm_predictions = svm.predict(X_test)\n","poly_svm_pred = svm_poly.predict(X_test)\n","rbf_svm_pred = svm_rbf.predict(X_test)\n","random_forest_predictions = random_forest.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"B2-HFM5EWpWv"},"source":["### Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRELmRqgWpWv","outputId":"f43e531a-1d3c-45d7-d5db-4d027466b162"},"outputs":[],"source":["linear_svm_metrics = trainer.get_metrics(Y_test, svm_predictions)\n","poly_svm_metrics = trainer.get_metrics(Y_test, poly_svm_pred)\n","rbf_svm_metrics = trainer.get_metrics(Y_test, rbf_svm_pred)\n","rdf_metrics = trainer.get_metrics(Y_test, random_forest_predictions)\n","\n","print(f'linear SVM accuracy: {linear_svm_metrics['accuracy_score']}')\n","print(f'poly SVM accuracy: {poly_svm_metrics['accuracy_score']}')\n","print(f'rbf SVM accuracy: {rbf_svm_metrics['accuracy_score']}')\n","print(f'RDF accuracy: {rdf_metrics['accuracy_score']}')\n","print()\n","print(f'linear SVM f1: {linear_svm_metrics['f1_score']}')\n","print(f'poly SVM f1: {poly_svm_metrics['f1_score']}')\n","print(f'rbf SVM f1: {rbf_svm_metrics['f1_score']}')\n","print(f'RDF f1: {rdf_metrics['f1_score']}')\n","print()\n","print(f'linear SVM precision: {linear_svm_metrics['precision_score']}')\n","print(f'poly SVM precision: {poly_svm_metrics['precision_score']}')\n","print(f'rbf SVM precision: {rbf_svm_metrics['precision_score']}')\n","print(f'RDF precision: {rdf_metrics['precision_score']}')\n","print()\n","print(f'linear SVM recall: {linear_svm_metrics['recall_score']}')\n","print(f'poly SVM recall: {poly_svm_metrics['recall_score']}')\n","print(f'rbf SVM recall: {rbf_svm_metrics['recall_score']}')\n","print(f'RDF recall: {rdf_metrics['recall_score']}')"]},{"cell_type":"markdown","metadata":{},"source":["### Random Search"]},{"cell_type":"markdown","metadata":{"id":"ksXrYnZvWpWw"},"source":["RandomizedSearch SVM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xi0dfI10WpWw","outputId":"f0f38ec1-888a-4f13-e779-d55d947bd1be"},"outputs":[],"source":["param_grid_svm = {\n","    'C': reciprocal(0.001, 1000),\n","    'gamma': expon(scale=1.0),\n","    'kernel': ['linear', 'rbf', 'poly']\n","}\n","\n","svm_clf = SVC(random_state=42)\n","random_search_svm = RandomizedSearchCV(svm_clf, param_distributions=param_grid_svm, n_iter=20, verbose=3, cv=5, random_state=42, n_jobs=-1, scoring = 'f1_macro')\n","random_search_svm.fit(X_train, Y_train)\n","print(\"Best parameters for SVM:\", random_search_svm.best_params_)\n","print(\"Best score:\", random_search_svm.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"CGtuCW1TWpWx"},"source":["RandomizedSearch Random Forest Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-VWUBi65WpWx"},"outputs":[],"source":["param_grid_rf = {\n","    'n_estimators': [80, 100, 200],\n","    'max_depth': [3, 4, 5, None],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'max_features': ['sqrt', 'log2', None]\n","}\n","\n","rfc = RandomForestClassifier(random_state=42)\n","\n","random_search_rf = RandomizedSearchCV(rfc, param_distributions=param_grid_rf, n_iter=20, cv=5, verbose=3, random_state=42, n_jobs=-1, scoring = 'f1_macro')\n","random_search_rf.fit(X_train, Y_train)\n","print(\"Best parameters:\", random_search_rf.best_params_)\n","print(\"Best score:\", random_search_rf.best_score_)"]},{"cell_type":"markdown","metadata":{},"source":["### Training with best parameters"]},{"cell_type":"markdown","metadata":{},"source":["#### SVM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["c = 0.1767016940294795\n","gamma = 3.010121430917521\n","new_svm = SVC(verbose=3, C=c, gamma=gamma, kernel='poly' )\n","print('Training SVM')\n","new_svm.fit(X_train, Y_train)\n","preds = new_svm.predict(X_test)\n","metrics = trainer.get_metrics(Y_test, preds)\n","print()\n","print(f'Accuracy: {metrics['accuracy_score']}')\n","print(f'F1: {metrics['f1_score']}')\n","print(f'Precision: {metrics['precision_score']}')\n","print(f'Recall: {metrics['recall_score']}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["c = 10\n","new_svm = SVC(verbose=3, C=c, gamma='auto', kernel='rbf' )\n","print('Training SVM')\n","new_svm.fit(X_train, Y_train)\n","preds = new_svm.predict(X_test)\n","metrics = trainer.get_metrics(Y_test, preds)\n","print()\n","print(f'Accuracy: {metrics['accuracy_score']}')\n","print(f'F1: {metrics['f1_score']}')\n","print(f'Precision: {metrics['precision_score']}')\n","print(f'Recall: {metrics['recall_score']}')"]},{"cell_type":"markdown","metadata":{},"source":["#### Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_estimators = 200 \n","min_samples_split = 5\n","min_samples_leaf = 4\n","\n","new_rdf = RandomForestClassifier(verbose=3, n_estimators=n_estimators, \n","                                 min_samples_split=min_samples_split, \n","                                 min_samples_leaf=min_samples_leaf, \n","                                 max_features='sqrt', max_depth=None)\n","new_rdf.fit(X_train, Y_train)\n","preds = new_rdf.predict(X_test)\n","metrics = trainer.get_metrics(Y_test, preds)\n","print()\n","print(f'Accuracy: {metrics['accuracy_score']}')\n","print(f'F1: {metrics['f1_score']}')\n","print(f'Precision: {metrics['precision_score']}')\n","print(f'Recall: {metrics['recall_score']}')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft\n",
    "from mutagen.wave import WAVE\n",
    "from parselmouth.praat import call\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import parselmouth\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Features Processing<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(path, type):\n",
    "    audio = WAVE(f'./wav_files/{type}/' + path)\n",
    "    audio_info = audio.info\n",
    "    return audio_info.length\n",
    "\n",
    "train_df = pd.read_csv('./wav_files/train/train_data.csv')\n",
    "train_df['Length'] = train_df['paths'].apply(lambda x: get_length(x, 'train'))\n",
    "\n",
    "test_df = pd.read_csv('./wav_files/test/test_data.csv')\n",
    "test_df['Length'] = test_df['paths'].apply(lambda x: get_length(x, 'test'))\n",
    "\n",
    "validation_df = pd.read_csv('./wav_files/validation/validation_data.csv')\n",
    "validation_df['Length'] = validation_df['paths'].apply(lambda x: get_length(x, 'validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get MFCCs ###\n",
    "def get_Normalized_Mfccs(data, sample_rate):\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=25)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_std = np.std(mfccs, axis=1)\n",
    "    mfccs_normalized = ((mfccs.T - mfccs_mean).T) / mfccs_std[:, np.newaxis]\n",
    "    return mfccs_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spectral measurements ###\n",
    "def get_spectral_measurements(data, sample_rate):\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=data, sr=sample_rate)[0]\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=data, sr=sample_rate)[0]\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=data, sr=sample_rate)[0]\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=data)[0]\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=data, sr=sample_rate)\n",
    "    return (spectral_centroids, spectral_rolloff, spectral_bandwidth, spectral_flatness, spectral_contrast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the pitch sequence\n",
    "def get_pitch_sequences(data, sample_rate):\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=data, sr=sample_rate)\n",
    "    # Select the dominant pitch at each frame\n",
    "    pitch_track = []\n",
    "    for t in range(pitches.shape[1]):\n",
    "        index = magnitudes[:, t].argmax()\n",
    "        pitch = pitches[index, t]\n",
    "        pitch_track.append(pitch)\n",
    "\n",
    "    pitch_track = np.array(pitch_track)\n",
    "\n",
    "    # Remove zeros values (unvoiced frames)\n",
    "    pitch_track = pitch_track[pitch_track > 0]\n",
    "    return pitch_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get formants data ###\n",
    "def get_formants(path):\n",
    "    audio = parselmouth.Sound(path)\n",
    "    formants = audio.to_formant_burg()\n",
    "    number_points = int(audio.duration / 0.01) + 1\n",
    "    formant_data = {'time': [], 'F1': [], 'F2': [], 'F3': []}\n",
    "    for i in range(number_points):\n",
    "        time = i * 0.01\n",
    "        formant_data['time'].append(time)\n",
    "        formant_data['F1'].append(formants.get_value_at_time(1, time))\n",
    "        formant_data['F2'].append(formants.get_value_at_time(2, time))\n",
    "        formant_data['F3'].append(formants.get_value_at_time(3, time))\n",
    "\n",
    "    return formant_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Energy and Amplitude Features ###\n",
    "\n",
    "def get_rms_energy(data):\n",
    "    # Root Mean Square (RMS) Energy - with a frame length of 2048 (default)\n",
    "    return librosa.feature.rms(y=data, frame_length=2048, hop_length=512)\n",
    "\n",
    "def get_ZCR(data):\n",
    "    # Zero-Crossing Rate (ZCR) - with a frame length of 2048 (default)\n",
    "    return librosa.feature.zero_crossing_rate(y=data, frame_length=2048, hop_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Voice Quality Features ###\n",
    "def get_HNR(data, sample_rate):\n",
    "    # Load the cleaned sound into parselmouth.Sound\n",
    "    snd = parselmouth.Sound(data, sample_rate)\n",
    "    # Harmonics-to-Noise Ratio (HNR)\n",
    "    hnr = call(snd, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    #print(hnr)\n",
    "    hnr_mean = call(hnr, \"Get mean\", 0, 0)\n",
    "    return hnr_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_df = pd.DataFrame()\n",
    "training_audios = train_df['paths'].tolist()\n",
    "test_audios = test_df['paths'].tolist()\n",
    "validation_audios = validation_df['paths'].tolist()\n",
    "\n",
    "for audio in validation_audios:\n",
    "    path = './wav_files/validation/' + audio\n",
    "    print(path)\n",
    "    #sample_rate represent the number of samples per seconds in the original signal.\n",
    "    data, sample_rate = librosa.load(path, sr=None)\n",
    "    #clean data\n",
    "    data = nr.reduce_noise(y=data, sr=sample_rate)\n",
    "\n",
    "    #Get the attributes\n",
    "    mfccs = get_Normalized_Mfccs(data, sample_rate)\n",
    "    specs_measurements = get_spectral_measurements(data, sample_rate)\n",
    "    pitch_track = get_pitch_sequences(data, sample_rate)\n",
    "    formants_data = get_formants(path)\n",
    "    rms_energy = get_rms_energy(data)\n",
    "    zcr = get_ZCR(data)\n",
    "    hnr_mean = get_HNR(data, sample_rate)\n",
    "\n",
    "    row = pd.DataFrame({'Audio': audio ,'MFCCs': [np.array(mfccs)], \n",
    "                                'Spec Centroid': [specs_measurements[0]], 'Spec Rollof': [specs_measurements[1]],\n",
    "                                'Spec Bandwidth': [specs_measurements[2]], 'Spec Flatness': [specs_measurements[3]], \n",
    "                                'Spec Contrast': [specs_measurements[4]], 'Pitch Track': [pitch_track],\n",
    "                                'Formants': [formants_data], 'RMS Energy': [rms_energy],\n",
    "                                'ZCR': [zcr], 'HNR Mean': [hnr_mean]})\n",
    "    attributes_df = pd.concat([attributes_df, row], ignore_index=True)\n",
    "\n",
    "\n",
    "attributes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Features visualisation<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialisation ###\n",
    "data, sample_rate = librosa.load(path=f'./wav_files/validation/{validation_df['paths'][0]}')\n",
    "data = nr.reduce_noise(y=data, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MFCCs visualisation ###\n",
    "\n",
    "normalized_mfccs = get_Normalized_Mfccs(data, sample_rate)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "librosa.display.specshow(normalized_mfccs, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCCs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spectral visualisation ###\n",
    "specs = get_spectral_measurements(data, sample_rate)\n",
    "\n",
    "t = librosa.frames_to_time(range(len(specs[0])), sr=sample_rate)\n",
    "\n",
    "# Plotting the Spectral Features\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t, specs[0], color='red', label='Centroid')\n",
    "plt.plot(t, specs[1], color='blue', label='Rolloff')\n",
    "plt.plot(t, specs[2], color='green', label='Bandwidth')\n",
    "\n",
    "# For spectral flatness, there's no need to convert to dB since it's a ratio and typically small.\n",
    "#plt.plot(t, spectral_flatness, color='orange', label='Flatness')\n",
    "\n",
    "# For spectral contrast, it's common to average over the frequency bands since it returns an array of shape (n_bands, n_frames).\n",
    "#spectral_contrast_avg = np.mean(spectral_contrast, axis=0)\n",
    "#plt.plot(t, spectral_contrast_avg, color='black', label='Contrast')\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Spectral Feature Value\")\n",
    "plt.title(\"Spectral Features Over Time\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pitches visualisation ###\n",
    "pitch_track = get_pitch_sequences(data, sample_rate)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(pitch_track)\n",
    "plt.xlabel('Time (frames)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title('Pitch Track')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RMS Visualisation  ###\n",
    "rms_energy = get_rms_energy(data)\n",
    "# Plotting the results (e.g., RMS Energy over time)\n",
    "frames = range(len(rms_energy[0]))\n",
    "t = librosa.frames_to_time(frames, sr=sample_rate)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t, rms_energy[0], label='RMS Energy')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Energy\")\n",
    "plt.title(\"RMS Energy Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
